{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Chenw/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-4-27 torch 1.11.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_00159_d_0000001.txt\n",
      "Image 0 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_00611_d_0000002.txt\n",
      "Image 1 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_01111_d_0000003.txt\n",
      "Image 2 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_01275_d_0000004.txt\n",
      "Image 3 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_01659_d_0000004.txt\n",
      "Image 4 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_02138_d_0000006.txt\n",
      "Image 5 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_02616_d_0000007.txt\n",
      "Image 6 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_03636_d_0000009.txt\n",
      "Image 7 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_04050_d_0000010.txt\n",
      "Image 8 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_04309_d_0000011.txt\n",
      "Image 9 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_05168_d_0000013.txt\n",
      "Image 10 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_05208_d_0000014.txt\n",
      "Image 11 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_05575_d_0000016.txt\n",
      "Image 12 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_05999_d_0000017.txt\n",
      "Image 13 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_06773_d_0000018.txt\n",
      "Image 14 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000006_07596_d_0000020.txt\n",
      "Image 15 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_00234_d_0000001.txt\n",
      "Image 16 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_01350_d_0000003.txt\n",
      "Image 17 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_01955_d_0000004.txt\n",
      "Image 18 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_02800_d_0000005.txt\n",
      "Image 19 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_04202_d_0000007.txt\n",
      "Image 20 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_05068_d_0000008.txt\n",
      "Image 21 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_06000_d_0000009.txt\n",
      "Image 22 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_06595_d_0000010.txt\n",
      "Image 23 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_07307_d_0000011.txt\n",
      "Image 24 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000011_08299_d_0000012.txt\n",
      "Image 25 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000054_00786_d_0000001.txt\n",
      "Image 26 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_00500_d_0000001.txt\n",
      "Image 27 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_02235_d_0000003.txt\n",
      "Image 28 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_03139_d_0000004.txt\n",
      "Image 29 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_04000_d_0000005.txt\n",
      "Image 30 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_05000_d_0000006.txt\n",
      "Image 31 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_06000_d_0000007.txt\n",
      "Image 32 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_07000_d_0000008.txt\n",
      "Image 33 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_08000_d_0000009.txt\n",
      "Image 34 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_08995_d_0000010.txt\n",
      "Image 35 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_10000_d_0000011.txt\n",
      "Image 36 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_11000_d_0000012.txt\n",
      "Image 37 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_11817_d_0000013.txt\n",
      "Image 38 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000063_12500_d_0000014.txt\n",
      "Image 39 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000066_01097_d_0000002.txt\n",
      "Image 40 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_00377_d_0000001.txt\n",
      "Image 41 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_01275_d_0000002.txt\n",
      "Image 42 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_03155_d_0000004.txt\n",
      "Image 43 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_04009_d_0000005.txt\n",
      "Image 44 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_05010_d_0000006.txt\n",
      "Image 45 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000073_05999_d_0000007.txt\n",
      "Image 46 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_01218_d_0000002.txt\n",
      "Image 47 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_02723_d_0000005.txt\n",
      "Image 48 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_03738_d_0000007.txt\n",
      "Image 49 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_05715_d_0000011.txt\n",
      "Image 50 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_06746_d_0000013.txt\n",
      "Image 51 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_07297_d_0000014.txt\n",
      "Image 52 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_07850_d_0000015.txt\n",
      "Image 53 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_08202_d_0000016.txt\n",
      "Image 54 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_08777_d_0000017.txt\n",
      "Image 55 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_09738_d_0000019.txt\n",
      "Image 56 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_10218_d_0000020.txt\n",
      "Image 57 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_10730_d_0000021.txt\n",
      "Image 58 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_11362_d_0000022.txt\n",
      "Image 59 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_11827_d_0000023.txt\n",
      "Image 60 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_12322_d_0000024.txt\n",
      "Image 61 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_13313_d_0000026.txt\n",
      "Image 62 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_13875_d_0000027.txt\n",
      "Image 63 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_14850_d_0000029.txt\n",
      "Image 64 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_15298_d_0000030.txt\n",
      "Image 65 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_15793_d_0000031.txt\n",
      "Image 66 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000074_16210_d_0000032.txt\n",
      "Image 67 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_00490_d_0000002.txt\n",
      "Image 68 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_01314_d_0000004.txt\n",
      "Image 69 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_01938_d_0000006.txt\n",
      "Image 70 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_02363_d_0000007.txt\n",
      "Image 71 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_02778_d_0000008.txt\n",
      "Image 72 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_03171_d_0000009.txt\n",
      "Image 73 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_03315_d_0000010.txt\n",
      "Image 74 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_03810_d_0000011.txt\n",
      "Image 75 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_04210_d_0000012.txt\n",
      "Image 76 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_04546_d_0000013.txt\n",
      "Image 77 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_05467_d_0000015.txt\n",
      "Image 78 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_05939_d_0000016.txt\n",
      "Image 79 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_06363_d_0000017.txt\n",
      "Image 80 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_06506_d_0000018.txt\n",
      "Image 81 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_06586_d_0000019.txt\n",
      "Image 82 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_06777_d_0000020.txt\n",
      "Image 83 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_07266_d_0000021.txt\n",
      "Image 84 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000078_07819_d_0000023.txt\n",
      "Image 85 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000083_00803_d_0000003.txt\n",
      "Image 86 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000087_00009_d_0000001.txt\n",
      "Image 87 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000087_00299_d_0000002.txt\n",
      "Image 88 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000087_00700_d_0000003.txt\n",
      "Image 89 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000087_01140_d_0000004.txt\n",
      "Image 90 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000087_01580_d_0000005.txt\n",
      "Image 91 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_01556_d_0000069.txt\n",
      "Image 92 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_01748_d_0000070.txt\n",
      "Image 93 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_02201_d_0000071.txt\n",
      "Image 94 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_02539_d_0000072.txt\n",
      "Image 95 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_02747_d_0000073.txt\n",
      "Image 96 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000105_02931_d_0000074.txt\n",
      "Image 97 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000118_02327_d_0000076.txt\n",
      "Image 98 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000118_02632_d_0000077.txt\n",
      "Image 99 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000120_00559_d_0000092.txt\n",
      "Image 100 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000120_01392_d_0000094.txt\n",
      "Image 101 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000120_01535_d_0000095.txt\n",
      "Image 102 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000120_02001_d_0000096.txt\n",
      "Image 103 is finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  slice_result = torch.tensor(slice_result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is saved at: cache\\result\\0000120_02946_d_0000098.txt\n",
      "Image 104 is finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi_yolo_test.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi_yolo_test.ipynb#ch0000000?line=10'>11</a>\u001b[0m image_path \u001b[39m=\u001b[39m image_paths[idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi_yolo_test.ipynb#ch0000000?line=11'>12</a>\u001b[0m img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(image_folder, image_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi_yolo_test.ipynb#ch0000000?line=12'>13</a>\u001b[0m sliced_results \u001b[39m=\u001b[39m single_img_train(img_path, cache_path, cache_path, yolo_model, \u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi_yolo_test.ipynb#ch0000000?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mImage \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(idx) \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m is finished\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chenw\\OneDrive\\Documents\\2022Spring\\EC523\\Project\\code\\sahi.py:72\u001b[0m, in \u001b[0;36msingle_img_train\u001b[1;34m(img_path, cache_path, res_path, model, h, w)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi.py?line=69'>70</a>\u001b[0m slice_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(sliced_image_path, slice_name)\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi.py?line=70'>71</a>\u001b[0m \u001b[39m# sliced_images.append(Image.open(slice_path))\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi.py?line=71'>72</a>\u001b[0m results \u001b[39m=\u001b[39m model(slice_path)\u001b[39m.\u001b[39mxyxy[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi.py?line=73'>74</a>\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/OneDrive/Documents/2022Spring/EC523/Project/code/sahi.py?line=74'>75</a>\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m j \u001b[39m*\u001b[39m block_width\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:567\u001b[0m, in \u001b[0;36mAutoShape.forward\u001b[1;34m(self, imgs, size, augment, profile)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=562'>563</a>\u001b[0m t\u001b[39m.\u001b[39mappend(time_sync())\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=564'>565</a>\u001b[0m \u001b[39mwith\u001b[39;00m amp\u001b[39m.\u001b[39mautocast(autocast):\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=565'>566</a>\u001b[0m     \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=566'>567</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, augment, profile)  \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=567'>568</a>\u001b[0m     t\u001b[39m.\u001b[39mappend(time_sync())\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=569'>570</a>\u001b[0m     \u001b[39m# Post-process\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:414\u001b[0m, in \u001b[0;36mDetectMultiBackend.forward\u001b[1;34m(self, im, augment, visualize, val)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=411'>412</a>\u001b[0m b, ch, h, w \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mshape  \u001b[39m# batch, channel, height, width\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=412'>413</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=413'>414</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=414'>415</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=415'>416</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:135\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=132'>133</a>\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_augment(x)  \u001b[39m# augmented inference, None\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=134'>135</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_once(x, profile, visualize)\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:158\u001b[0m, in \u001b[0;36mModel._forward_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=155'>156</a>\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=156'>157</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=157'>158</a>\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=158'>159</a>\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py?line=159'>160</a>\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:50\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='file:///c%3A/Users/Chenw/.cache/torch/hub/ultralytics_yolov5_master/models/common.py?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\.conda\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/Chenw/.conda/envs/yolo/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sahi import single_img_train\n",
    "import os\n",
    "\n",
    "image_folder = r\"images\"\n",
    "image_paths = os.listdir(image_folder)\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "cache_path = r\"cache\"\n",
    "\n",
    "for idx in range(0, len(image_paths)):\n",
    "    image_path = image_paths[idx]\n",
    "    img_path = os.path.join(image_folder, image_path)\n",
    "    sliced_results = single_img_train(img_path, cache_path, cache_path, yolo_model, 10,10)\n",
    "    print(\"Image \" + str(idx) +\" is finished\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b62cfcd9f0c3c8814b10206c9760fc5205a4b54de2de896e06866023fc4e5cce"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('yolo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
